#+title: Experiment Log

* SAE notebook - setup
:PROPERTIES:
:CREATED:  <2025-10-08 Wed> [01:43]
:END:

Niestety wygląda na to że na SAE Lens/transformer lens ma problemy...
Na RTX model poprawnie ma średnią L0 ~ 301 ale na MPS jest to z 1.5k



* Thresholding pursuit
:PROPERTIES:
:CREATED:  <2025-10-11 Sat> [18:34]
:END:

Odpaliłem coś takiego (acts=Y jest $B \times L \times H$, $W_{dec}$ jest $D \times H$ - rozmiar słownika razy rozmiar warstwy ukrytej)

#+BEGIN_SRC python :session experiment_log.org  :exports both
def sparse_lstq(A, Y, support):
    """
    find X
    A[:,support]X = Y
    """
    A_in = A[support].float().T
    Y_in = Y.float().T
    coefficients = torch.linalg.lstsq(A_in, Y_in).solution.T
    x = torch.zeros(Y.shape[0], A.shape[0]).to(Y.device)
    x[:,support] = coefficients
    return x

def instance_thresholding_support(W_dec, y, topk):
    """
    get support like in thresholding algorithm and then fit linear regression on this support
    """
    return torch.topk((y @ W_dec.T).abs(), topk, dim=-1).indices.flatten().unique()


def instance_thresholding_pursuit(acts, W_dec, topk):
    x = torch.zeros(*acts.shape[:2], W_dec.shape[0]).to(acts.device).half()
    for i in range(acts.shape[0]):
        Y = acts[i]
        support = instance_thresholding_support(W_dec, acts, topk)
        coeffs = sparse_lstq(W_dec, Y, support)

        x[i] = coeffs
    return x
#+END_SRC

W skrócie biorę nośnik topk per

** Ciekawe obserwacje
:PROPERTIES:
:CREATED:  <2025-10-11 Sat> [18:39]
:END:

To jest z SAE

#+BEGIN_SRC python :session experiment_log.org  :exports both
sae_config = dict(

    release="gemma-scope-2b-pt-res",  # see other options in sae_lens/pretrained_saes.yaml
    sae_id="layer_19/width_16k/average_l0_279",
)
#+END_SRC


#+BEGIN_QUOTE
Orig 3.2734375
###
sae nonzero
l0 per token: 315.0157470703125
l0 per instance: 6891.25
reconstr_sae 3.73046875
###
iht nonzero
l0 per token: 86.93897247314453
l0 per instance: 3329.5
reconstr_iht 3.9453125
###
instance iht nonzero
l0 per token: 55.86023712158203
l0 per instance: 2643.75
reconstr_instance_iht 3.931640625
###
pursuit nonzero
l0 per token: 280.2775573730469
l0 per instance: 530.0
reconstr_instance_thresholding_pursuit 3.953125
###
Zero 12.453125
#+END_QUOTE

Czyli wygląda jakby dla tego modelu który ma dosyć wysokie l0 nasz model miał per-token podobne l0
ale za to per cały tekst u nas jest znacznie lepiej

Co zabawniej to jak l0 SAE jest niższe to ten instance pursuit ma lepszą stratę, oczywiście wyższe l0 per token
ale i tak dalej per instancja l0 jest mniejsze



* SAEBench
:PROPERTIES:
:CREATED:  <2025-10-13 Mon> [22:55]
:END:

Ten notebook w repo można wykorzystać z customowymi SAE

Notebook odpala ich ewaluację i można go użyć do porównania paru modeli

** SAEBench - integracja
:PROPERTIES:
:CREATED:  <2025-10-15 Wed> [00:09]
:END:

Dodałem InstanceHardThresholdingSAE (nazwa może nie do końca fortunna)
i wyciągnąłem moduły do dopasowywania modelu liniowego i thresholdingu

* MPSAE
:PROPERTIES:
:CREATED:  <2025-10-16 Thu> [00:03]
:END:

Okazuje się że faktycznie są prace z SAE opartym o zachłannym matching pursuit.
Tak jak możnaby się spodziewać działają podobnie ale lepiej niż wyjściowe SAE (i nie mają tych dziwnych akcji z L0 co w moim podejściu)

* SAEBench cd
:PROPERTIES:
:CREATED:  <2025-10-16 Thu> [00:04]
:END:

Zaimplementowałem loadery pod SAEBench, ale nie mogę odpalić demo SAEBench w sae_research przez konflikt wersji
** Metryki

SAEBench ma swietna strone na Neuronpedii

https://www.neuronpedia.org/sae-bench/info

** SAEBench demo

Odpalilem MPSAE i IHTPSAE w SAEBench - dzialaja i jedyny problem jest na koncu ze sparse probe (ale ten blad juz w sumie wychodzil tez bez tych SAE)

** DVC
:PROPERTIES:
:CREATED:  <2025-10-18 sob> [13:46]
:END:



* Negative Results for SAEs On Downstream Tasks and Deprioritising SAE Research (GDM Mech Interp Team Progress Update #2)
:PROPERTIES:
:CREATED:  <2025-10-20 pon> [23:26]
:END:

https://www.alignmentforum.org/posts/4uXCAJNuPKtKBsi28/sae-progress-update-2-draft
W tym poście jest sygnalizowane że SAE wyglądają na ślepą uliczkę, ALE w zasadzie to autorzy sami wymienili potencjalnie przydatne kierunki:

#+BEGIN_QUOTE
There are also other valuable projects, for example, *are there much cheaper ways we can train SAEs of acceptable quality? Or to get similar effects with other feature clustering or dictionary learning methods instead?* If we’re taking a pragmatic approach to SAEs, rather than the ambitious approach of trying to find the canonical units of analysis, then sacrificing some quality in return for lowering the major up front cost of SAE training may be worthwhile.
#+END_QUOTE

** Nurt 1 - zachłanne metody dekodowania i ich korzyści
:PROPERTIES:
:CREATED:  <2025-10-20 pon> [23:29]
:END:

*are there much cheaper ways we can train SAEs of acceptable quality? Or to get similar effects with other feature clustering or dictionary learning methods instead?*

Jedyną pracą która wykorzystuje zachłanne metody dekodowania jest ta z MPSAE https://arxiv.org/pdf/2506.05239v1
ale ta praca wykorzystuje tylko zachłanne dekodowanie /jako architekturę/, a nie jako coś co można użyć do wytrenowanego SAE.

*** Hipoteza: dzięki zachłannemu dekodowaniu można pominąć trenowanie dla wielu hiperparametrów
:PROPERTIES:
:CREATED:  <2025-10-20 pon> [23:34]
:END:

Opiera się to na prostej obserwacji że metodami zachłannymi możemy sprowadzić model z wysokim $k$, powiedzmy 500, do $k=100$

Eksperyment: sprawdzamy modele np TopK z różnym $k$ i porównujemy je do tego co otrzymaliśmy zachłannym dekodowaniem z modelu z najwyższym $k$



* Pomysły z architekturą
:PROPERTIES:
:CREATED:  <2025-10-20 pon> [23:19]
:END:

** DONE Reprodukcja modeli z SAEBench
:PROPERTIES:
:CREATED:  <2025-10-20 pon> [23:16]
:END:

Wygląda na to że modele do SAEBench były trenowane przez skrypt w dictionary_learning_demo

Oryginalnie to jest używane z 500M tokenów ale w sumie mnie bardziej podoba się pomysł żeby używać 5M (a potem może 50M) żeby przyspiszyć eksperymenty

** DONE Modele z pursuit/progowaniem
:PROPERTIES:
:CREATED:  <2025-10-20 pon> [23:19]
:END:

https://github.com/adamkarvonen/dictionary_learning_demo/compare/main...lambdaofgod:dictionary_learning_demo:main

Dodane trenowanie "zagnieżdżonych" topk SAE z progowaniem

* [#A] quasi-orthogonal
:PROPERTIES:
:CREATED:  <2025-10-22 śro> [21:48]
:END:

[[cite:&lee25_evaluat_desig_spars_autoen_by]]

Ta praca explicite rozważa mutual coherence, ale wiele jej brakuje
to ograniczenie z Johnsona-Lindenstraussa jest dużo słabsze - ograniczenia RIP
mają dużo więcej sensu

* Open problem in MI C*4.26
:PROPERTIES:
:CREATED:  <2025-10-30 czw> [22:03]
:END:

#+BEGIN_QUOTE
C* 4.26 - Can you find any examples of locally almost-orthogonal bases? That is, where correlated features each get their own direction, but can interfere significantly with un/anti-correlated features.
#+END_QUOTE

* take: algebraic geometry
:PROPERTIES:
:CREATED:  <2025-10-30 czw> [21:58]
:END:

** IDEA orthogonal rows - unit columns
:PROPERTIES:
:CREATED:  <2025-10-30 czw> [21:56]
:END:

$A$ is an $n \times p$ matrix such that

$AA^T = diag(v)$ where $v$ is some vector and $\|A_:,i\| = 1$

This is an algebraic variety

** equiangular frames
:PROPERTIES:
:CREATED:  <2025-10-30 czw> [21:58]
:END:

Here the problem is that equiangularity is encoded by $A^T A$

How to make this less crazy:
- apply regularization in-batch on selected columns


* Embedder SAE
:PROPERTIES:
:CREATED:  <2025-11-29 Sat> [12:05]
:END:

Trenowanie tych SAE dla embedderów jest dosyć prosto osiągnąć za pomocą sentence-transformers

** trenowanie na fineweb
:PROPERTIES:
:CREATED:  <2025-11-29 sob> [14:19]
:END:

Bez dodania znormalizowanego MSE ten model zdawal sie nie bardzo czegos uczyc (okazalo sie to mega wazne bo np norma gradientu teraz nie jest jakas mikroskopijna)



* Feature aggregation/subspaces 
:PROPERTIES:
:CREATED:  <2026-01-08 Thu> [15:21]
:END:

In experiments/sparse_subspace_clustering/ssc.org I experimented with the method from  [[id:db133c45-664d-4845-9c98-618336646582][Not All Language Model Features Are One-Dimensionally Linear]] and compared it to subspace clustering and the clusters/subspaces from SSC look better than the method from the paper

** How to compare the feature families 
:PROPERTIES:
:CREATED:  <2026-01-08 Thu> [15:37]
:END:

- angles between subspaces
